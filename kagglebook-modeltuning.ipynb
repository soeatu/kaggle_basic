{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1bc5350",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-05T14:39:49.477910Z",
     "iopub.status.busy": "2023-04-05T14:39:49.477500Z",
     "iopub.status.idle": "2023-04-05T14:40:16.889658Z",
     "shell.execute_reply": "2023-04-05T14:40:16.888289Z"
    },
    "papermill": {
     "duration": 27.427377,
     "end_time": "2023-04-05T14:40:16.892197",
     "exception": false,
     "start_time": "2023-04-05T14:39:49.464820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting japanize-matplotlib\r\n",
      "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from japanize-matplotlib) (3.5.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->japanize-matplotlib) (9.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib->japanize-matplotlib) (1.21.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->japanize-matplotlib) (23.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->japanize-matplotlib) (4.38.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->japanize-matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->japanize-matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->japanize-matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->japanize-matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->japanize-matplotlib) (4.4.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.16.0)\r\n",
      "Building wheels for collected packages: japanize-matplotlib\r\n",
      "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120275 sha256=31d5102df97bcf8d6920a83c79529f0c006314b7f0671e3807df7c9bbb996f6b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/7d/c5/d3e02382561888f86edabf3256c09b3298f8e24456f8fc4da3\r\n",
      "Successfully built japanize-matplotlib\r\n",
      "Installing collected packages: japanize-matplotlib\r\n",
      "Successfully installed japanize-matplotlib-1.1.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: pandas_profiling in /opt/conda/lib/python3.7/site-packages (3.6.2)\r\n",
      "Collecting pandas_profiling\r\n",
      "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting ydata-profiling\r\n",
      "  Downloading ydata_profiling-4.1.2-py2.py3-none-any.whl (345 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.9/345.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: phik<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (0.12.3)\r\n",
      "Requirement already satisfied: typeguard<2.14,>=2.13.2 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (2.13.3)\r\n",
      "Requirement already satisfied: tqdm<4.65,>=4.48.2 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (4.64.1)\r\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.5 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (0.7.5)\r\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (6.0)\r\n",
      "Requirement already satisfied: imagehash==4.3.1 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (4.3.1)\r\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (3.1.2)\r\n",
      "Requirement already satisfied: scipy<1.10,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.7.3)\r\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.3.5)\r\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (0.1.12)\r\n",
      "Requirement already satisfied: multimethod<1.10,>=1.4 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.9.1)\r\n",
      "Requirement already satisfied: pydantic<1.11,>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.10.4)\r\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (0.13.5)\r\n",
      "Requirement already satisfied: requests<2.29,>=2.24.0 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (2.28.2)\r\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (0.12.2)\r\n",
      "Requirement already satisfied: matplotlib<3.7,>=3.2 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (3.5.3)\r\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from ydata-profiling->pandas_profiling) (1.21.6)\r\n",
      "Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.7/site-packages (from imagehash==4.3.1->ydata-profiling->pandas_profiling) (1.3.0)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from imagehash==4.3.1->ydata-profiling->pandas_profiling) (9.4.0)\r\n",
      "Requirement already satisfied: attrs>=19.3.0 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (22.2.0)\r\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (0.2.0)\r\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (2.6.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas_profiling) (2.1.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (1.4.4)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (0.11.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (23.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (3.0.9)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (4.38.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas_profiling) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>1.1->ydata-profiling->pandas_profiling) (2022.7.1)\r\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas_profiling) (1.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from pydantic<1.11,>=1.8.1->ydata-profiling->pandas_profiling) (4.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas_profiling) (2.1.1)\r\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels<0.14,>=0.13.2->ydata-profiling->pandas_profiling) (0.5.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->ydata-profiling->pandas_profiling) (1.16.0)\r\n",
      "Installing collected packages: ydata-profiling, pandas_profiling\r\n",
      "  Attempting uninstall: pandas_profiling\r\n",
      "    Found existing installation: pandas-profiling 3.6.2\r\n",
      "    Uninstalling pandas-profiling-3.6.2:\r\n",
      "      Successfully uninstalled pandas-profiling-3.6.2\r\n",
      "Successfully installed pandas_profiling-3.6.6 ydata-profiling-4.1.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 必要ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 前処理\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# バリデーション\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "# 評価指標\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# モデリング: lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# matplotilbで日本語表示したい場合はこれをinstallしてインポートする\n",
    "!pip install japanize-matplotlib\n",
    "import japanize_matplotlib\n",
    "\n",
    "# 2022/06/02追加: Kaggle notebook環境変更のため\n",
    "!pip install -U pandas_profiling\n",
    "\n",
    "# 分布確認\n",
    "import pandas_profiling as pdp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29407411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:40:16.919241Z",
     "iopub.status.busy": "2023-04-05T14:40:16.918873Z",
     "iopub.status.idle": "2023-04-05T14:40:16.958806Z",
     "shell.execute_reply": "2023-04-05T14:40:16.957324Z"
    },
    "papermill": {
     "duration": 0.056123,
     "end_time": "2023-04-05T14:40:16.960688",
     "exception": false,
     "start_time": "2023-04-05T14:40:16.904565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "df_train.head()\n",
    "\n",
    "#Excelファイル　df = pd.read_excel(\"ファイル名\")\n",
    "#タブ区切り　　　df = pd_read_CSV(\"sample.tst\", sep=\"\\t\")\n",
    "#Shift JIS形式のCSVファイル　df = pd.read_CSV(\"sample.csv\", encoding=\"Shift_jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4991fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:40:16.987658Z",
     "iopub.status.busy": "2023-04-05T14:40:16.987266Z",
     "iopub.status.idle": "2023-04-05T14:40:16.998390Z",
     "shell.execute_reply": "2023-04-05T14:40:16.997222Z"
    },
    "papermill": {
     "duration": 0.028323,
     "end_time": "2023-04-05T14:40:17.001156",
     "exception": false,
     "start_time": "2023-04-05T14:40:16.972833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2) (891, 1) (891, 1)\n"
     ]
    }
   ],
   "source": [
    "#データセット作成\n",
    "x_train, y_train, id_train = df_train[[\"Pclass\", \"Fare\"]], \\\n",
    "                             df_train[[\"Survived\"]], \\\n",
    "                             df_train[[\"PassengerId\"]]\n",
    "print(x_train.shape, y_train.shape, id_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a36624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:40:17.027776Z",
     "iopub.status.busy": "2023-04-05T14:40:17.027422Z",
     "iopub.status.idle": "2023-04-05T14:40:17.432158Z",
     "shell.execute_reply": "2023-04-05T14:40:17.430979Z"
    },
    "papermill": {
     "duration": 0.421506,
     "end_time": "2023-04-05T14:40:17.435174",
     "exception": false,
     "start_time": "2023-04-05T14:40:17.013668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ベイズ最適化\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9010fec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:40:17.461839Z",
     "iopub.status.busy": "2023-04-05T14:40:17.461482Z",
     "iopub.status.idle": "2023-04-05T14:40:17.474575Z",
     "shell.execute_reply": "2023-04-05T14:40:17.472828Z"
    },
    "papermill": {
     "duration": 0.029397,
     "end_time": "2023-04-05T14:40:17.477117",
     "exception": false,
     "start_time": "2023-04-05T14:40:17.447720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#目的関数の定義\n",
    "# 探索しないハイパーパラメータ\n",
    "params_base = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.02,\n",
    "    'n_estimators': 100000,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"seed\": 123,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # 探索するハイパーパラメータ\n",
    "    params_tuning = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 256),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 200),\n",
    "        \"min_sum_hessian_in_leaf\": trial.suggest_float(\"min_sum_hessian_in_leaf\", 1e-5, 1e-2, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-2, 1e2, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-2, 1e2, log=True),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x_train, y_train))\n",
    "    for nfold in np.arange(5):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = x_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = x_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "        model = lgb.LGBMClassifier(**params_tuning)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(x_tr,y_tr), (x_va,y_va)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0,\n",
    "                 )\n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "    \n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543ec345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:40:17.503784Z",
     "iopub.status.busy": "2023-04-05T14:40:17.503361Z",
     "iopub.status.idle": "2023-04-05T14:41:51.067648Z",
     "shell.execute_reply": "2023-04-05T14:41:51.066836Z"
    },
    "papermill": {
     "duration": 93.580223,
     "end_time": "2023-04-05T14:41:51.069891",
     "exception": false,
     "start_time": "2023-04-05T14:40:17.489668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:17,506]\u001b[0m A new study created in memory with name: no-name-fb1f8b2b-8634-4942-bc39-152406d7818a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:20,589]\u001b[0m Trial 0 finished with value: 0.664478061640826 and parameters: {'num_leaves': 181, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 4.792414358623587e-05, 'feature_fraction': 0.7756573845414456, 'bagging_fraction': 0.8597344848927815, 'lambda_l1': 0.492522233779106, 'lambda_l2': 83.76388146302445}. Best is trial 0 with value: 0.664478061640826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:22,441]\u001b[0m Trial 1 finished with value: 0.6712196346745339 and parameters: {'num_leaves': 178, 'min_data_in_leaf': 99, 'min_sum_hessian_in_leaf': 0.00015009027543233888, 'feature_fraction': 0.6715890080754348, 'bagging_fraction': 0.8645248536920208, 'lambda_l1': 0.567922374174008, 'lambda_l2': 0.01732652966363563}. Best is trial 1 with value: 0.6712196346745339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:24,026]\u001b[0m Trial 2 finished with value: 0.65762350134957 and parameters: {'num_leaves': 107, 'min_data_in_leaf': 149, 'min_sum_hessian_in_leaf': 3.52756635172055e-05, 'feature_fraction': 0.5877258780737462, 'bagging_fraction': 0.7657756869209191, 'lambda_l1': 1.3406343673102123, 'lambda_l2': 3.4482904089131434}. Best is trial 1 with value: 0.6712196346745339.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:25,270]\u001b[0m Trial 3 finished with value: 0.6722302429226037 and parameters: {'num_leaves': 219, 'min_data_in_leaf': 146, 'min_sum_hessian_in_leaf': 0.0006808799287054756, 'feature_fraction': 0.8612216912851107, 'bagging_fraction': 0.6614794569265892, 'lambda_l1': 0.2799978022399009, 'lambda_l2': 0.08185645330667264}. Best is trial 3 with value: 0.6722302429226037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:26,670]\u001b[0m Trial 4 finished with value: 0.668972443663298 and parameters: {'num_leaves': 81, 'min_data_in_leaf': 128, 'min_sum_hessian_in_leaf': 1.889360449174926e-05, 'feature_fraction': 0.7168505863397641, 'bagging_fraction': 0.7154313816648219, 'lambda_l1': 0.9434967110751797, 'lambda_l2': 0.5050346330980694}. Best is trial 3 with value: 0.6722302429226037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:28,283]\u001b[0m Trial 5 finished with value: 0.6587847592743706 and parameters: {'num_leaves': 85, 'min_data_in_leaf': 88, 'min_sum_hessian_in_leaf': 0.004788147156768277, 'feature_fraction': 0.9720800091019398, 'bagging_fraction': 0.7509183379421682, 'lambda_l1': 3.1319282717196035, 'lambda_l2': 0.029005047452739414}. Best is trial 3 with value: 0.6722302429226037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:28,655]\u001b[0m Trial 6 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 87, 'min_data_in_leaf': 86, 'min_sum_hessian_in_leaf': 0.003971252247766701, 'feature_fraction': 0.6252276826982534, 'bagging_fraction': 0.7415171321313522, 'lambda_l1': 87.54657140659076, 'lambda_l2': 1.1965765212602313}. Best is trial 3 with value: 0.6722302429226037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:33,503]\u001b[0m Trial 7 finished with value: 0.6992530286862093 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.0030131614432849746, 'feature_fraction': 0.8015300642054637, 'bagging_fraction': 0.7725340032332324, 'lambda_l1': 0.23499322154972468, 'lambda_l2': 0.1646202117975735}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:35,624]\u001b[0m Trial 8 finished with value: 0.6823363254033017 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 138, 'min_sum_hessian_in_leaf': 0.00423029374725911, 'feature_fraction': 0.7552111687390055, 'bagging_fraction': 0.8346568914811361, 'lambda_l1': 2.206714812711709, 'lambda_l2': 3.1594683442464033}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:36,636]\u001b[0m Trial 9 finished with value: 0.6362751867428285 and parameters: {'num_leaves': 175, 'min_data_in_leaf': 170, 'min_sum_hessian_in_leaf': 1.7765808030254076e-05, 'feature_fraction': 0.8818414207216692, 'bagging_fraction': 0.6218331872684371, 'lambda_l1': 0.05982625838323253, 'lambda_l2': 1.9490717640641542}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0010167214653943027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0010167214653943027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0010167214653943027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0010167214653943027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0010167214653943027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0010167214653943027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0010167214653943027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0010167214653943027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0010167214653943027, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0010167214653943027\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:39,886]\u001b[0m Trial 10 finished with value: 0.673435440336451 and parameters: {'num_leaves': 32, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 0.0010167214653943027, 'feature_fraction': 0.5040305717020102, 'bagging_fraction': 0.9940542446575642, 'lambda_l1': 0.010612397212799423, 'lambda_l2': 0.1661409929489422}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.575475056267361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.575475056267361\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.23255529096855, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.23255529096855\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7633477525641262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7633477525641262\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.575475056267361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.575475056267361\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.23255529096855, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.23255529096855\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7633477525641262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7633477525641262\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.575475056267361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.575475056267361\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.23255529096855, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.23255529096855\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7633477525641262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7633477525641262\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.575475056267361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.575475056267361\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.23255529096855, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.23255529096855\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7633477525641262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7633477525641262\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.575475056267361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.575475056267361\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.23255529096855, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.23255529096855\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7633477525641262, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7633477525641262\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:40,888]\u001b[0m Trial 11 finished with value: 0.6509949155734104 and parameters: {'num_leaves': 141, 'min_data_in_leaf': 198, 'min_sum_hessian_in_leaf': 0.009951069387483545, 'feature_fraction': 0.7633477525641262, 'bagging_fraction': 0.575475056267361, 'lambda_l1': 6.343590915843685, 'lambda_l2': 8.23255529096855}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.12924644318960654, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12924644318960654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8385815299651418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8385815299651418\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8001581267589792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8001581267589792\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12924644318960654, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12924644318960654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8385815299651418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8385815299651418\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8001581267589792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8001581267589792\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12924644318960654, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12924644318960654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8385815299651418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8385815299651418\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8001581267589792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8001581267589792\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12924644318960654, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12924644318960654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8385815299651418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8385815299651418\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8001581267589792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8001581267589792\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12924644318960654, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12924644318960654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8385815299651418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8385815299651418\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8001581267589792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8001581267589792\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:48,069]\u001b[0m Trial 12 finished with value: 0.6756512459983679 and parameters: {'num_leaves': 255, 'min_data_in_leaf': 18, 'min_sum_hessian_in_leaf': 0.001634914743632515, 'feature_fraction': 0.8001581267589792, 'bagging_fraction': 0.8385815299651418, 'lambda_l1': 0.12924644318960654, 'lambda_l2': 0.2669531355707319}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=7.775399875398035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.775399875398035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5285693047324076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5285693047324076\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0699652461442427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0699652461442427\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6920119879687722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920119879687722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.775399875398035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.775399875398035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5285693047324076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5285693047324076\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0699652461442427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0699652461442427\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6920119879687722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920119879687722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.775399875398035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.775399875398035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5285693047324076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5285693047324076\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0699652461442427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0699652461442427\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6920119879687722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920119879687722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.775399875398035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.775399875398035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5285693047324076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5285693047324076\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0699652461442427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0699652461442427\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6920119879687722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920119879687722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.775399875398035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.775399875398035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5285693047324076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5285693047324076\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0699652461442427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0699652461442427\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6920119879687722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920119879687722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:49,360]\u001b[0m Trial 13 finished with value: 0.673404054987132 and parameters: {'num_leaves': 140, 'min_data_in_leaf': 43, 'min_sum_hessian_in_leaf': 0.0021756690901938718, 'feature_fraction': 0.6920119879687722, 'bagging_fraction': 0.5285693047324076, 'lambda_l1': 7.775399875398035, 'lambda_l2': 0.0699652461442427}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0620290262968281, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0620290262968281\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5343541416013556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5343541416013556\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259582777932722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259582777932722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00043809038647614484, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00043809038647614484\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0620290262968281, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0620290262968281\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5343541416013556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5343541416013556\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259582777932722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259582777932722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00043809038647614484, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00043809038647614484\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0620290262968281, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0620290262968281\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5343541416013556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5343541416013556\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259582777932722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259582777932722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00043809038647614484, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00043809038647614484\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0620290262968281, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0620290262968281\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5343541416013556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5343541416013556\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259582777932722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259582777932722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00043809038647614484, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00043809038647614484\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0620290262968281, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0620290262968281\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5343541416013556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5343541416013556\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8259582777932722, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8259582777932722\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00043809038647614484, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00043809038647614484\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:52,378]\u001b[0m Trial 14 finished with value: 0.676743456154667 and parameters: {'num_leaves': 31, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 0.00043809038647614484, 'feature_fraction': 0.8259582777932722, 'bagging_fraction': 0.8148189817022143, 'lambda_l1': 0.0620290262968281, 'lambda_l2': 0.5343541416013556}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=2.3717491322043136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3717491322043136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9342289692301791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9342289692301791\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.214148908060242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.214148908060242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7363755369144015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7363755369144015\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009795048869631716, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009795048869631716\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3717491322043136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3717491322043136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9342289692301791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9342289692301791\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.214148908060242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.214148908060242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7363755369144015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7363755369144015\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009795048869631716, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009795048869631716\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3717491322043136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3717491322043136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9342289692301791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9342289692301791\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.214148908060242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.214148908060242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7363755369144015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7363755369144015\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009795048869631716, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009795048869631716\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3717491322043136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3717491322043136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9342289692301791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9342289692301791\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.214148908060242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.214148908060242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7363755369144015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7363755369144015\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009795048869631716, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009795048869631716\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3717491322043136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3717491322043136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9342289692301791, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9342289692301791\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.214148908060242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.214148908060242\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7363755369144015, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7363755369144015\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009795048869631716, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009795048869631716\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:54,277]\u001b[0m Trial 15 finished with value: 0.6700207143305504 and parameters: {'num_leaves': 118, 'min_data_in_leaf': 121, 'min_sum_hessian_in_leaf': 0.009795048869631716, 'feature_fraction': 0.7363755369144015, 'bagging_fraction': 0.9342289692301791, 'lambda_l1': 2.3717491322043136, 'lambda_l2': 7.214148908060242}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.24824579193576923, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24824579193576923\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.684561345587239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.684561345587239\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01033528363848504, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01033528363848504\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9130458751266737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9130458751266737\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002540361858194928, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002540361858194928\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24824579193576923, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24824579193576923\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.684561345587239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.684561345587239\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01033528363848504, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01033528363848504\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9130458751266737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9130458751266737\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002540361858194928, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002540361858194928\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24824579193576923, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24824579193576923\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.684561345587239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.684561345587239\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01033528363848504, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01033528363848504\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9130458751266737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9130458751266737\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002540361858194928, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002540361858194928\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24824579193576923, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24824579193576923\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.684561345587239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.684561345587239\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01033528363848504, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01033528363848504\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9130458751266737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9130458751266737\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002540361858194928, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002540361858194928\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24824579193576923, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24824579193576923\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.684561345587239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.684561345587239\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01033528363848504, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01033528363848504\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9130458751266737, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9130458751266737\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002540361858194928, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002540361858194928\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:57,148]\u001b[0m Trial 16 finished with value: 0.665601657146444 and parameters: {'num_leaves': 58, 'min_data_in_leaf': 36, 'min_sum_hessian_in_leaf': 0.0002540361858194928, 'feature_fraction': 0.9130458751266737, 'bagging_fraction': 0.684561345587239, 'lambda_l1': 0.24824579193576923, 'lambda_l2': 0.01033528363848504}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=13.036514166467544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13.036514166467544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8036823783112217, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8036823783112217\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8807586136754733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8807586136754733\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8159485991955707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8159485991955707\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0023269108543753883, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0023269108543753883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=13.036514166467544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13.036514166467544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8036823783112217, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8036823783112217\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8807586136754733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8807586136754733\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8159485991955707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8159485991955707\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0023269108543753883, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0023269108543753883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=13.036514166467544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13.036514166467544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8036823783112217, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8036823783112217\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8807586136754733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8807586136754733\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8159485991955707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8159485991955707\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0023269108543753883, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0023269108543753883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=13.036514166467544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13.036514166467544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8036823783112217, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8036823783112217\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8807586136754733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8807586136754733\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8159485991955707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8159485991955707\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0023269108543753883, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0023269108543753883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:57,949]\u001b[0m Trial 17 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 157, 'min_data_in_leaf': 168, 'min_sum_hessian_in_leaf': 0.0023269108543753883, 'feature_fraction': 0.8159485991955707, 'bagging_fraction': 0.8036823783112217, 'lambda_l1': 13.036514166467544, 'lambda_l2': 0.8807586136754733}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=13.036514166467544, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13.036514166467544\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8036823783112217, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8036823783112217\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8807586136754733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8807586136754733\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8159485991955707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8159485991955707\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0023269108543753883, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0023269108543753883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=168, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=168\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8859038983275196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8859038983275196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7896979370510073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7896979370510073\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2497145849301042, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2497145849301042\n",
      "[LightGBM] [Warning] feature_fraction is set=0.745392277347916, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.745392277347916\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009561825756709678, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009561825756709678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8859038983275196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8859038983275196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7896979370510073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7896979370510073\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2497145849301042, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2497145849301042\n",
      "[LightGBM] [Warning] feature_fraction is set=0.745392277347916, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.745392277347916\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009561825756709678, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009561825756709678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8859038983275196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8859038983275196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7896979370510073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7896979370510073\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2497145849301042, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2497145849301042\n",
      "[LightGBM] [Warning] feature_fraction is set=0.745392277347916, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.745392277347916\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009561825756709678, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009561825756709678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8859038983275196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8859038983275196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7896979370510073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7896979370510073\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2497145849301042, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2497145849301042\n",
      "[LightGBM] [Warning] feature_fraction is set=0.745392277347916, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.745392277347916\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009561825756709678, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009561825756709678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8859038983275196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8859038983275196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7896979370510073, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7896979370510073\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2497145849301042, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2497145849301042\n",
      "[LightGBM] [Warning] feature_fraction is set=0.745392277347916, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.745392277347916\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009561825756709678, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009561825756709678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:40:59,468]\u001b[0m Trial 18 finished with value: 0.6487477245621744 and parameters: {'num_leaves': 218, 'min_data_in_leaf': 113, 'min_sum_hessian_in_leaf': 0.0009561825756709678, 'feature_fraction': 0.745392277347916, 'bagging_fraction': 0.7896979370510073, 'lambda_l1': 1.8859038983275196, 'lambda_l2': 0.2497145849301042}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.6420140723743011, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6420140723743011\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962774263442048, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962774263442048\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08240013163620977, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08240013163620977\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8343848232650426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8343848232650426\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00470022827464237, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00470022827464237\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6420140723743011, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6420140723743011\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962774263442048, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962774263442048\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08240013163620977, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08240013163620977\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8343848232650426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8343848232650426\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00470022827464237, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00470022827464237\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6420140723743011, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6420140723743011\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962774263442048, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962774263442048\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08240013163620977, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08240013163620977\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8343848232650426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8343848232650426\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00470022827464237, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00470022827464237\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6420140723743011, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6420140723743011\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962774263442048, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962774263442048\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08240013163620977, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08240013163620977\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8343848232650426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8343848232650426\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00470022827464237, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00470022827464237\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6420140723743011, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6420140723743011\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962774263442048, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962774263442048\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08240013163620977, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08240013163620977\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8343848232650426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8343848232650426\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00470022827464237, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00470022827464237\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:02,536]\u001b[0m Trial 19 finished with value: 0.6767622873642584 and parameters: {'num_leaves': 214, 'min_data_in_leaf': 73, 'min_sum_hessian_in_leaf': 0.00470022827464237, 'feature_fraction': 0.8343848232650426, 'bagging_fraction': 0.8962774263442048, 'lambda_l1': 0.6420140723743011, 'lambda_l2': 0.08240013163620977}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.15470937382525465, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15470937382525465\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7128489974232202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7128489974232202\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2609218276420697, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2609218276420697\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9182676696103418, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9182676696103418\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=141, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=141\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15470937382525465, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15470937382525465\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7128489974232202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7128489974232202\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2609218276420697, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2609218276420697\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9182676696103418, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9182676696103418\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=141, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=141\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15470937382525465, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15470937382525465\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7128489974232202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7128489974232202\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2609218276420697, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2609218276420697\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9182676696103418, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9182676696103418\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=141, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=141\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15470937382525465, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15470937382525465\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7128489974232202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7128489974232202\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2609218276420697, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2609218276420697\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9182676696103418, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9182676696103418\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=141, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=141\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15470937382525465, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15470937382525465\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7128489974232202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7128489974232202\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2609218276420697, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2609218276420697\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9182676696103418, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9182676696103418\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=141, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=141\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:04,428]\u001b[0m Trial 20 finished with value: 0.6632477559475237 and parameters: {'num_leaves': 8, 'min_data_in_leaf': 141, 'min_sum_hessian_in_leaf': 0.0013845801360137025, 'feature_fraction': 0.9182676696103418, 'bagging_fraction': 0.7128489974232202, 'lambda_l1': 0.15470937382525465, 'lambda_l2': 2.2609218276420697}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.7703796368033595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7703796368033595\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8950870417609795, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8950870417609795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04354863183028053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04354863183028053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8567769598292199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8567769598292199\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004346880252436188, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004346880252436188\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7703796368033595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7703796368033595\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8950870417609795, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8950870417609795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04354863183028053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04354863183028053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8567769598292199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8567769598292199\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004346880252436188, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004346880252436188\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7703796368033595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7703796368033595\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8950870417609795, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8950870417609795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04354863183028053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04354863183028053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8567769598292199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8567769598292199\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004346880252436188, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004346880252436188\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7703796368033595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7703796368033595\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8950870417609795, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8950870417609795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04354863183028053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04354863183028053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8567769598292199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8567769598292199\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004346880252436188, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004346880252436188\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7703796368033595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7703796368033595\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8950870417609795, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8950870417609795\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04354863183028053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04354863183028053\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8567769598292199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8567769598292199\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004346880252436188, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004346880252436188\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:07,195]\u001b[0m Trial 21 finished with value: 0.6767622873642584 and parameters: {'num_leaves': 202, 'min_data_in_leaf': 69, 'min_sum_hessian_in_leaf': 0.004346880252436188, 'feature_fraction': 0.8567769598292199, 'bagging_fraction': 0.8950870417609795, 'lambda_l1': 0.7703796368033595, 'lambda_l2': 0.04354863183028053}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.39491924434752995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.39491924434752995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9188562305409576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9188562305409576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11699060869869958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11699060869869958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.797120322493883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.797120322493883\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0029312159809115365, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0029312159809115365\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.39491924434752995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.39491924434752995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9188562305409576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9188562305409576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11699060869869958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11699060869869958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.797120322493883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.797120322493883\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0029312159809115365, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0029312159809115365\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.39491924434752995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.39491924434752995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9188562305409576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9188562305409576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11699060869869958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11699060869869958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.797120322493883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.797120322493883\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0029312159809115365, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0029312159809115365\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.39491924434752995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.39491924434752995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9188562305409576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9188562305409576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11699060869869958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11699060869869958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.797120322493883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.797120322493883\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0029312159809115365, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0029312159809115365\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.39491924434752995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.39491924434752995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9188562305409576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9188562305409576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11699060869869958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11699060869869958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.797120322493883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.797120322493883\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0029312159809115365, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0029312159809115365\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:12,599]\u001b[0m Trial 22 finished with value: 0.6835791852363318 and parameters: {'num_leaves': 242, 'min_data_in_leaf': 39, 'min_sum_hessian_in_leaf': 0.0029312159809115365, 'feature_fraction': 0.797120322493883, 'bagging_fraction': 0.9188562305409576, 'lambda_l1': 0.39491924434752995, 'lambda_l2': 0.11699060869869958}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.35966599755660583, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35966599755660583\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148059316157261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148059316157261\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10619688398329478, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10619688398329478\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7805825622868416, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7805825622868416\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0025767028972243115, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0025767028972243115\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35966599755660583, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35966599755660583\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148059316157261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148059316157261\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10619688398329478, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10619688398329478\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7805825622868416, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7805825622868416\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0025767028972243115, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0025767028972243115\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35966599755660583, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35966599755660583\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148059316157261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148059316157261\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10619688398329478, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10619688398329478\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7805825622868416, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7805825622868416\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0025767028972243115, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0025767028972243115\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35966599755660583, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35966599755660583\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148059316157261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148059316157261\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10619688398329478, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10619688398329478\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7805825622868416, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7805825622868416\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0025767028972243115, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0025767028972243115\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35966599755660583, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35966599755660583\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148059316157261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148059316157261\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10619688398329478, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10619688398329478\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7805825622868416, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7805825622868416\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0025767028972243115, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0025767028972243115\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:16,948]\u001b[0m Trial 23 finished with value: 0.6858263762475676 and parameters: {'num_leaves': 238, 'min_data_in_leaf': 35, 'min_sum_hessian_in_leaf': 0.0025767028972243115, 'feature_fraction': 0.7805825622868416, 'bagging_fraction': 0.8148059316157261, 'lambda_l1': 0.35966599755660583, 'lambda_l2': 0.10619688398329478}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.2892838767901096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2892838767901096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777147743387992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777147743387992\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15562933607555834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15562933607555834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7910081527344837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7910081527344837\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0022135465987980587, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0022135465987980587\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2892838767901096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2892838767901096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777147743387992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777147743387992\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15562933607555834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15562933607555834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7910081527344837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7910081527344837\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0022135465987980587, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0022135465987980587\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2892838767901096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2892838767901096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777147743387992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777147743387992\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15562933607555834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15562933607555834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7910081527344837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7910081527344837\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0022135465987980587, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0022135465987980587\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2892838767901096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2892838767901096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777147743387992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777147743387992\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15562933607555834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15562933607555834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7910081527344837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7910081527344837\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0022135465987980587, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0022135465987980587\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2892838767901096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2892838767901096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777147743387992, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777147743387992\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15562933607555834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15562933607555834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7910081527344837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7910081527344837\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0022135465987980587, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0022135465987980587\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:21,508]\u001b[0m Trial 24 finished with value: 0.6903207582700396 and parameters: {'num_leaves': 249, 'min_data_in_leaf': 35, 'min_sum_hessian_in_leaf': 0.0022135465987980587, 'feature_fraction': 0.7910081527344837, 'bagging_fraction': 0.777147743387992, 'lambda_l1': 0.2892838767901096, 'lambda_l2': 0.15562933607555834}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.09570534249544699, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09570534249544699\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7888189187157192, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7888189187157192\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.039817678953394185, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.039817678953394185\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7879963202697107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7879963202697107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017613624830553707, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017613624830553707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09570534249544699, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09570534249544699\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7888189187157192, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7888189187157192\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.039817678953394185, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.039817678953394185\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7879963202697107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7879963202697107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017613624830553707, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017613624830553707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09570534249544699, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09570534249544699\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7888189187157192, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7888189187157192\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.039817678953394185, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.039817678953394185\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7879963202697107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7879963202697107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017613624830553707, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017613624830553707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09570534249544699, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09570534249544699\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7888189187157192, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7888189187157192\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.039817678953394185, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.039817678953394185\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7879963202697107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7879963202697107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017613624830553707, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017613624830553707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09570534249544699, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09570534249544699\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7888189187157192, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7888189187157192\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.039817678953394185, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.039817678953394185\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7879963202697107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7879963202697107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017613624830553707, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017613624830553707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:28,096]\u001b[0m Trial 25 finished with value: 0.6981545414600465 and parameters: {'num_leaves': 239, 'min_data_in_leaf': 24, 'min_sum_hessian_in_leaf': 0.0017613624830553707, 'feature_fraction': 0.7879963202697107, 'bagging_fraction': 0.7888189187157192, 'lambda_l1': 0.09570534249544699, 'lambda_l2': 0.039817678953394185}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.06361154197572774, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06361154197572774\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7759869529031096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759869529031096\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029506192029373737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029506192029373737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7156691855196431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156691855196431\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006918172538679483, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006918172538679483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06361154197572774, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06361154197572774\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7759869529031096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759869529031096\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029506192029373737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029506192029373737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7156691855196431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156691855196431\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006918172538679483, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006918172538679483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06361154197572774, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06361154197572774\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7759869529031096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759869529031096\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029506192029373737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029506192029373737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7156691855196431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156691855196431\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006918172538679483, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006918172538679483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06361154197572774, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06361154197572774\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7759869529031096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759869529031096\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029506192029373737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029506192029373737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7156691855196431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156691855196431\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006918172538679483, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006918172538679483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06361154197572774, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06361154197572774\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7759869529031096, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759869529031096\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029506192029373737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029506192029373737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7156691855196431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7156691855196431\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006918172538679483, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006918172538679483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:32,567]\u001b[0m Trial 26 finished with value: 0.6520431862406628 and parameters: {'num_leaves': 196, 'min_data_in_leaf': 18, 'min_sum_hessian_in_leaf': 0.0006918172538679483, 'feature_fraction': 0.7156691855196431, 'bagging_fraction': 0.7759869529031096, 'lambda_l1': 0.06361154197572774, 'lambda_l2': 0.029506192029373737}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7775152269204683, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775152269204683\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03981834857329031, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03981834857329031\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7981086348840757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7981086348840757\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0015110604476009741, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0015110604476009741\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7775152269204683, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775152269204683\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03981834857329031, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03981834857329031\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7981086348840757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7981086348840757\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0015110604476009741, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0015110604476009741\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7775152269204683, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775152269204683\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03981834857329031, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03981834857329031\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7981086348840757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7981086348840757\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0015110604476009741, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0015110604476009741\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7775152269204683, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775152269204683\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03981834857329031, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03981834857329031\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7981086348840757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7981086348840757\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0015110604476009741, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0015110604476009741\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7775152269204683, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7775152269204683\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03981834857329031, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03981834857329031\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7981086348840757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7981086348840757\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0015110604476009741, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0015110604476009741\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:45,135]\u001b[0m Trial 27 finished with value: 0.6824555897307136 and parameters: {'num_leaves': 253, 'min_data_in_leaf': 7, 'min_sum_hessian_in_leaf': 0.0015110604476009741, 'feature_fraction': 0.7981086348840757, 'bagging_fraction': 0.7775152269204683, 'lambda_l1': 0.13213697905758195, 'lambda_l2': 0.03981834857329031}. Best is trial 7 with value: 0.6992530286862093.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.05156762599756539, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05156762599756539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7317397959755858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7317397959755858\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20885772437641695, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20885772437641695\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8426315000433712, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8426315000433712\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0068112646256021986, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0068112646256021986\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05156762599756539, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05156762599756539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7317397959755858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7317397959755858\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20885772437641695, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20885772437641695\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8426315000433712, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8426315000433712\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0068112646256021986, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0068112646256021986\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05156762599756539, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05156762599756539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7317397959755858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7317397959755858\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20885772437641695, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20885772437641695\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8426315000433712, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8426315000433712\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0068112646256021986, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0068112646256021986\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05156762599756539, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05156762599756539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7317397959755858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7317397959755858\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20885772437641695, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20885772437641695\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8426315000433712, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8426315000433712\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0068112646256021986, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0068112646256021986\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05156762599756539, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05156762599756539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7317397959755858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7317397959755858\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20885772437641695, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20885772437641695\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8426315000433712, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8426315000433712\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0068112646256021986, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0068112646256021986\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:48,798]\u001b[0m Trial 28 finished with value: 0.7048207896553889 and parameters: {'num_leaves': 233, 'min_data_in_leaf': 49, 'min_sum_hessian_in_leaf': 0.0068112646256021986, 'feature_fraction': 0.8426315000433712, 'bagging_fraction': 0.7317397959755858, 'lambda_l1': 0.05156762599756539, 'lambda_l2': 0.20885772437641695}. Best is trial 28 with value: 0.7048207896553889.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0223517282592696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0223517282592696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7326320350377127, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7326320350377127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.265177341262348, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.265177341262348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8381244831959944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8381244831959944\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.006296757603803257, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.006296757603803257\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0223517282592696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0223517282592696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7326320350377127, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7326320350377127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.265177341262348, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.265177341262348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8381244831959944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8381244831959944\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.006296757603803257, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.006296757603803257\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0223517282592696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0223517282592696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7326320350377127, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7326320350377127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.265177341262348, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.265177341262348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8381244831959944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8381244831959944\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.006296757603803257, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.006296757603803257\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0223517282592696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0223517282592696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7326320350377127, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7326320350377127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.265177341262348, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.265177341262348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8381244831959944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8381244831959944\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.006296757603803257, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.006296757603803257\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0223517282592696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0223517282592696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7326320350377127, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7326320350377127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.265177341262348, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.265177341262348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8381244831959944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8381244831959944\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.006296757603803257, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.006296757603803257\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-05 14:41:51,064]\u001b[0m Trial 29 finished with value: 0.6733915008474044 and parameters: {'num_leaves': 161, 'min_data_in_leaf': 57, 'min_sum_hessian_in_leaf': 0.006296757603803257, 'feature_fraction': 0.8381244831959944, 'bagging_fraction': 0.7326320350377127, 'lambda_l1': 0.0223517282592696, 'lambda_l2': 0.265177341262348}. Best is trial 28 with value: 0.7048207896553889.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#最適化処理（探査の実行）\n",
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4ba1db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.117258Z",
     "iopub.status.busy": "2023-04-05T14:41:51.116050Z",
     "iopub.status.idle": "2023-04-05T14:41:51.124130Z",
     "shell.execute_reply": "2023-04-05T14:41:51.122919Z"
    },
    "papermill": {
     "duration": 0.033484,
     "end_time": "2023-04-05T14:41:51.126063",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.092579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.7048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 233,\n",
       " 'min_data_in_leaf': 49,\n",
       " 'min_sum_hessian_in_leaf': 0.0068112646256021986,\n",
       " 'feature_fraction': 0.8426315000433712,\n",
       " 'bagging_fraction': 0.7317397959755858,\n",
       " 'lambda_l1': 0.05156762599756539,\n",
       " 'lambda_l2': 0.20885772437641695}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#探査の結果確認\n",
    "trial = study.best_trial\n",
    "print(\"acc(best)={:.4f}\".format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "233dcb7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.173273Z",
     "iopub.status.busy": "2023-04-05T14:41:51.172613Z",
     "iopub.status.idle": "2023-04-05T14:41:51.179325Z",
     "shell.execute_reply": "2023-04-05T14:41:51.177869Z"
    },
    "papermill": {
     "duration": 0.032644,
     "end_time": "2023-04-05T14:41:51.181353",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.148709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 233,\n",
       " 'min_data_in_leaf': 49,\n",
       " 'min_sum_hessian_in_leaf': 0.0068112646256021986,\n",
       " 'feature_fraction': 0.8426315000433712,\n",
       " 'bagging_fraction': 0.7317397959755858,\n",
       " 'lambda_l1': 0.05156762599756539,\n",
       " 'lambda_l2': 0.20885772437641695,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'objective': 'binary',\n",
       " 'metric': 'auc',\n",
       " 'learning_rate': 0.02,\n",
       " 'n_estimators': 100000,\n",
       " 'bagging_freq': 1,\n",
       " 'seed': 123}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ベストなハイパーパラメータの取得\n",
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5d894",
   "metadata": {
    "papermill": {
     "duration": 0.021741,
     "end_time": "2023-04-05T14:41:51.225405",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.203664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LightGBM以外のモデル利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76c6b26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.272126Z",
     "iopub.status.busy": "2023-04-05T14:41:51.271773Z",
     "iopub.status.idle": "2023-04-05T14:41:51.284062Z",
     "shell.execute_reply": "2023-04-05T14:41:51.282816Z"
    },
    "papermill": {
     "duration": 0.038951,
     "end_time": "2023-04-05T14:41:51.286494",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.247543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Titanicデータを用いた例：ロジスティクス回帰\n",
    "# ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "# データセット作成\n",
    "x_train = df_train[[\"Pclass\", \"Age\", \"Embarked\"]]\n",
    "y_train = df_train[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16437a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.336240Z",
     "iopub.status.busy": "2023-04-05T14:41:51.335886Z",
     "iopub.status.idle": "2023-04-05T14:41:51.348648Z",
     "shell.execute_reply": "2023-04-05T14:41:51.347385Z"
    },
    "papermill": {
     "duration": 0.04154,
     "end_time": "2023-04-05T14:41:51.351728",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.310188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Age         177\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欠損値の確認\n",
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b4df67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.400990Z",
     "iopub.status.busy": "2023-04-05T14:41:51.400632Z",
     "iopub.status.idle": "2023-04-05T14:41:51.412274Z",
     "shell.execute_reply": "2023-04-05T14:41:51.410990Z"
    },
    "papermill": {
     "duration": 0.039507,
     "end_time": "2023-04-05T14:41:51.415023",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.375516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間：数値データ 平均値補完\n",
    "x_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n",
    "\n",
    "# 欠損値補間：カテゴリ変数　最頻値補完\n",
    "x_train[\"Embarked\"] = x_train[\"Embarked\"].fillna(x_train[\"Embarked\"].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e513bf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.464182Z",
     "iopub.status.busy": "2023-04-05T14:41:51.463825Z",
     "iopub.status.idle": "2023-04-05T14:41:51.476673Z",
     "shell.execute_reply": "2023-04-05T14:41:51.475349Z"
    },
    "papermill": {
     "duration": 0.04016,
     "end_time": "2023-04-05T14:41:51.478934",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.438774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#カテゴリ変数の数値化（One-hot-encoding）\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(x_train[[\"Embarked\"]])\n",
    "df_embarked = pd.DataFrame(\n",
    "    ohe.transform(x_train[[\"Embarked\"]]).toarray(), \n",
    "    columns=[\"Embarked_{}\".format(col) for col in ohe.categories_[0]])\n",
    "\n",
    "x_train = pd.concat([x_train, df_embarked], axis=1)\n",
    "x_train = x_train.drop(columns=[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "476f1986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.528066Z",
     "iopub.status.busy": "2023-04-05T14:41:51.527715Z",
     "iopub.status.idle": "2023-04-05T14:41:51.535602Z",
     "shell.execute_reply": "2023-04-05T14:41:51.534609Z"
    },
    "papermill": {
     "duration": 0.035521,
     "end_time": "2023-04-05T14:41:51.537692",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.502171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#数値データの正規化\n",
    "x_train[\"Pclass\"] = (x_train[\"Pclass\"] -x_train[\"Pclass\"].min()) / (x_train[\"Pclass\"].max() - x_train[\"Pclass\"].min()) \n",
    "x_train[\"Age\"] = (x_train[\"Age\"] -x_train[\"Age\"].min()) / (x_train[\"Age\"].max() - x_train[\"Age\"].min()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0995cdc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.585748Z",
     "iopub.status.busy": "2023-04-05T14:41:51.585421Z",
     "iopub.status.idle": "2023-04-05T14:41:51.598358Z",
     "shell.execute_reply": "2023-04-05T14:41:51.596962Z"
    },
    "papermill": {
     "duration": 0.040897,
     "end_time": "2023-04-05T14:41:51.601428",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.560531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 5) (179, 5) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "#学習データと検証データの分割（ホールドアウト法）\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ac9b2be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.650265Z",
     "iopub.status.busy": "2023-04-05T14:41:51.649902Z",
     "iopub.status.idle": "2023-04-05T14:41:51.756783Z",
     "shell.execute_reply": "2023-04-05T14:41:51.755451Z"
    },
    "papermill": {
     "duration": 0.134252,
     "end_time": "2023-04-05T14:41:51.759217",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.624965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7263\n",
      "[0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression ロジスティクス回帰\n",
    "# モデル定義\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logis = LogisticRegression()\n",
    "\n",
    "# 学習\n",
    "model_logis.fit(x_tr, y_tr)\n",
    "\n",
    "# 予測\n",
    "y_va_pred = model_logis.predict(x_va)\n",
    "print(\"accuracy:{:.4f}\".format(accuracy_score(y_va, y_va_pred)))\n",
    "print(y_va_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5406daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.807559Z",
     "iopub.status.busy": "2023-04-05T14:41:51.807195Z",
     "iopub.status.idle": "2023-04-05T14:41:51.814662Z",
     "shell.execute_reply": "2023-04-05T14:41:51.813419Z"
    },
    "papermill": {
     "duration": 0.034022,
     "end_time": "2023-04-05T14:41:51.816880",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.782858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83621285 0.16378715]\n",
      " [0.23058311 0.76941689]\n",
      " [0.83244141 0.16755859]\n",
      " [0.32227072 0.67772928]\n",
      " [0.62569522 0.37430478]]\n"
     ]
    }
   ],
   "source": [
    "#確率値の取得\n",
    "y_va_pred_proba = model_logis.predict_proba(x_va)\n",
    "print(y_va_pred_proba[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6cb5a72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:51.865292Z",
     "iopub.status.busy": "2023-04-05T14:41:51.864897Z",
     "iopub.status.idle": "2023-04-05T14:41:51.962922Z",
     "shell.execute_reply": "2023-04-05T14:41:51.961792Z"
    },
    "papermill": {
     "duration": 0.125028,
     "end_time": "2023-04-05T14:41:51.965081",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.840053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7151\n",
      "[0 1 0 1 0]\n",
      "[[0.73985924 0.26014076]\n",
      " [0.28242534 0.71757466]\n",
      " [0.73986177 0.26013823]\n",
      " [0.26828214 0.73171786]\n",
      " [0.58950192 0.41049808]]\n"
     ]
    }
   ],
   "source": [
    "#Titanicデータを用いた例：SVM\n",
    "# モデル定義\n",
    "from sklearn.svm import SVC\n",
    "model_svm = SVC(C=1.0, random_state=123, probability=True)#確率値の計算するパラメータをTrue\n",
    "\n",
    "# 学習\n",
    "model_svm.fit(x_tr, y_tr)\n",
    "\n",
    "# 予測\n",
    "y_va_pred = model_svm.predict(x_va)\n",
    "print(\"accuracy:{:.4f}\".format(accuracy_score(y_va, y_va_pred)))\n",
    "print(y_va_pred[:5])\n",
    "\n",
    "# 確率値の取得\n",
    "y_va_pred_proba = model_svm.predict_proba(x_va)\n",
    "print(y_va_pred_proba[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a100e",
   "metadata": {
    "papermill": {
     "duration": 0.023994,
     "end_time": "2023-04-05T14:41:52.012165",
     "exception": false,
     "start_time": "2023-04-05T14:41:51.988171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ニューラルネットワーク\n",
    "### ニューラルネットワークの適用例：①全結合層のみのネットワークモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffb06e79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:41:52.061119Z",
     "iopub.status.busy": "2023-04-05T14:41:52.060758Z",
     "iopub.status.idle": "2023-04-05T14:42:00.284688Z",
     "shell.execute_reply": "2023-04-05T14:42:00.283474Z"
    },
    "papermill": {
     "duration": 8.251609,
     "end_time": "2023-04-05T14:42:00.287345",
     "exception": false,
     "start_time": "2023-04-05T14:41:52.035736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tensorflowインポート\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c33153c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:00.336170Z",
     "iopub.status.busy": "2023-04-05T14:42:00.335286Z",
     "iopub.status.idle": "2023-04-05T14:42:00.342469Z",
     "shell.execute_reply": "2023-04-05T14:42:00.341201Z"
    },
    "papermill": {
     "duration": 0.034315,
     "end_time": "2023-04-05T14:42:00.344972",
     "exception": false,
     "start_time": "2023-04-05T14:42:00.310657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorflowの再現性のためのシード指定\n",
    "def seed_everything(seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "250be99a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:00.393557Z",
     "iopub.status.busy": "2023-04-05T14:42:00.393060Z",
     "iopub.status.idle": "2023-04-05T14:42:00.405472Z",
     "shell.execute_reply": "2023-04-05T14:42:00.404422Z"
    },
    "papermill": {
     "duration": 0.039131,
     "end_time": "2023-04-05T14:42:00.407578",
     "exception": false,
     "start_time": "2023-04-05T14:42:00.368447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "# データセット作成\n",
    "x_train = df_train[[\"Pclass\", \"Age\", \"Embarked\"]]\n",
    "y_train = df_train[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d062964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:00.455434Z",
     "iopub.status.busy": "2023-04-05T14:42:00.454965Z",
     "iopub.status.idle": "2023-04-05T14:42:00.464063Z",
     "shell.execute_reply": "2023-04-05T14:42:00.463027Z"
    },
    "papermill": {
     "duration": 0.035412,
     "end_time": "2023-04-05T14:42:00.465963",
     "exception": false,
     "start_time": "2023-04-05T14:42:00.430551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間 平均値補完\n",
    "x_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n",
    "\n",
    "# 正規化　補完後に0~1に間になるように正規化\n",
    "for col in [\"Pclass\", \"Age\"]:\n",
    "    value_min = x_train[col].min()\n",
    "    value_max = x_train[col].max()\n",
    "    x_train[col] = (x_train[col] - value_min) / (value_max - value_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd9227de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:00.513636Z",
     "iopub.status.busy": "2023-04-05T14:42:00.513205Z",
     "iopub.status.idle": "2023-04-05T14:42:00.526263Z",
     "shell.execute_reply": "2023-04-05T14:42:00.525201Z"
    },
    "papermill": {
     "duration": 0.039543,
     "end_time": "2023-04-05T14:42:00.528402",
     "exception": false,
     "start_time": "2023-04-05T14:42:00.488859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間　最頻値で補完\n",
    "x_train[\"Embarked\"] = x_train[\"Embarked\"].fillna(x_train[\"Embarked\"].mode()[0])\n",
    "\n",
    "# one-hot-encodingで変換\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(x_train[[\"Embarked\"]])\n",
    "df_embarked = pd.DataFrame(ohe.transform(x_train[[\"Embarked\"]]).toarray(), \n",
    "                           columns=[\"Embarked_{}\".format(col) for col in ohe.categories_[0]])\n",
    "x_train = pd.concat([x_train.drop(columns=[\"Embarked\"]), \n",
    "                     df_embarked], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dcb61ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:00.577121Z",
     "iopub.status.busy": "2023-04-05T14:42:00.576754Z",
     "iopub.status.idle": "2023-04-05T14:42:00.591333Z",
     "shell.execute_reply": "2023-04-05T14:42:00.589786Z"
    },
    "papermill": {
     "duration": 0.042331,
     "end_time": "2023-04-05T14:42:00.594019",
     "exception": false,
     "start_time": "2023-04-05T14:42:00.551688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 5) (179, 5) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "# 学習データと検証データの分割\n",
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "563fcb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:00.643553Z",
     "iopub.status.busy": "2023-04-05T14:42:00.642966Z",
     "iopub.status.idle": "2023-04-05T14:42:00.922243Z",
     "shell.execute_reply": "2023-04-05T14:42:00.920656Z"
    },
    "papermill": {
     "duration": 0.306448,
     "end_time": "2023-04-05T14:42:00.924554",
     "exception": false,
     "start_time": "2023-04-05T14:42:00.618106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                60        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10)               40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 5)                20        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 331\n",
      "Trainable params: 281\n",
      "Non-trainable params: 50\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#モデル定義　カラム数5:入力ノード5 隠れ層=3 10/10/5\n",
    "def create_model():\n",
    "    input_num = Input(shape=(5,))\n",
    "    x_num = Dense(10, activation=\"relu\")(input_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.3)(x_num)\n",
    "    x_num = Dense(10, activation=\"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.2)(x_num)\n",
    "    x_num = Dense(5, activation=\"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.1)(x_num)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x_num)\n",
    "\n",
    "    model = Model(inputs=input_num,\n",
    "                  outputs=out,\n",
    "                 )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"binary_crossentropy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c7ea474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:00.977918Z",
     "iopub.status.busy": "2023-04-05T14:42:00.977531Z",
     "iopub.status.idle": "2023-04-05T14:42:10.510670Z",
     "shell.execute_reply": "2023-04-05T14:42:10.509451Z"
    },
    "papermill": {
     "duration": 9.562982,
     "end_time": "2023-04-05T14:42:10.513021",
     "exception": false,
     "start_time": "2023-04-05T14:42:00.950039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "83/89 [==========================>...] - ETA: 0s - loss: 0.7301 - binary_crossentropy: 0.7301\n",
      "Epoch 1: val_loss improved from inf to 0.68177, saving model to model_keras.h5\n",
      "89/89 [==============================] - 2s 6ms/step - loss: 0.7269 - binary_crossentropy: 0.7269 - val_loss: 0.6818 - val_binary_crossentropy: 0.6818 - lr: 0.0010\n",
      "Epoch 2/10000\n",
      "67/89 [=====================>........] - ETA: 0s - loss: 0.6795 - binary_crossentropy: 0.6795\n",
      "Epoch 2: val_loss improved from 0.68177 to 0.66743, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6733 - binary_crossentropy: 0.6733 - val_loss: 0.6674 - val_binary_crossentropy: 0.6674 - lr: 0.0010\n",
      "Epoch 3/10000\n",
      "88/89 [============================>.] - ETA: 0s - loss: 0.6762 - binary_crossentropy: 0.6762\n",
      "Epoch 3: val_loss improved from 0.66743 to 0.65250, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6751 - binary_crossentropy: 0.6751 - val_loss: 0.6525 - val_binary_crossentropy: 0.6525 - lr: 0.0010\n",
      "Epoch 4/10000\n",
      "65/89 [====================>.........] - ETA: 0s - loss: 0.6391 - binary_crossentropy: 0.6391\n",
      "Epoch 4: val_loss improved from 0.65250 to 0.63568, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6488 - binary_crossentropy: 0.6488 - val_loss: 0.6357 - val_binary_crossentropy: 0.6357 - lr: 0.0010\n",
      "Epoch 5/10000\n",
      "64/89 [====================>.........] - ETA: 0s - loss: 0.6639 - binary_crossentropy: 0.6639\n",
      "Epoch 5: val_loss improved from 0.63568 to 0.61948, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6567 - binary_crossentropy: 0.6567 - val_loss: 0.6195 - val_binary_crossentropy: 0.6195 - lr: 0.0010\n",
      "Epoch 6/10000\n",
      "74/89 [=======================>......] - ETA: 0s - loss: 0.6593 - binary_crossentropy: 0.6593\n",
      "Epoch 6: val_loss improved from 0.61948 to 0.61322, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6626 - binary_crossentropy: 0.6626 - val_loss: 0.6132 - val_binary_crossentropy: 0.6132 - lr: 0.0010\n",
      "Epoch 7/10000\n",
      "62/89 [===================>..........] - ETA: 0s - loss: 0.6534 - binary_crossentropy: 0.6534\n",
      "Epoch 7: val_loss did not improve from 0.61322\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6604 - binary_crossentropy: 0.6604 - val_loss: 0.6139 - val_binary_crossentropy: 0.6139 - lr: 0.0010\n",
      "Epoch 8/10000\n",
      "64/89 [====================>.........] - ETA: 0s - loss: 0.6480 - binary_crossentropy: 0.6480\n",
      "Epoch 8: val_loss improved from 0.61322 to 0.61166, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6404 - binary_crossentropy: 0.6404 - val_loss: 0.6117 - val_binary_crossentropy: 0.6117 - lr: 0.0010\n",
      "Epoch 9/10000\n",
      "64/89 [====================>.........] - ETA: 0s - loss: 0.6470 - binary_crossentropy: 0.6470\n",
      "Epoch 9: val_loss improved from 0.61166 to 0.60525, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6438 - binary_crossentropy: 0.6438 - val_loss: 0.6052 - val_binary_crossentropy: 0.6052 - lr: 0.0010\n",
      "Epoch 10/10000\n",
      "71/89 [======================>.......] - ETA: 0s - loss: 0.6357 - binary_crossentropy: 0.6357\n",
      "Epoch 10: val_loss did not improve from 0.60525\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_crossentropy: 0.6269 - val_loss: 0.6056 - val_binary_crossentropy: 0.6056 - lr: 0.0010\n",
      "Epoch 11/10000\n",
      "58/89 [==================>...........] - ETA: 0s - loss: 0.6400 - binary_crossentropy: 0.6400\n",
      "Epoch 11: val_loss improved from 0.60525 to 0.60281, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6453 - binary_crossentropy: 0.6453 - val_loss: 0.6028 - val_binary_crossentropy: 0.6028 - lr: 0.0010\n",
      "Epoch 12/10000\n",
      "65/89 [====================>.........] - ETA: 0s - loss: 0.6379 - binary_crossentropy: 0.6379\n",
      "Epoch 12: val_loss improved from 0.60281 to 0.60200, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6310 - binary_crossentropy: 0.6310 - val_loss: 0.6020 - val_binary_crossentropy: 0.6020 - lr: 0.0010\n",
      "Epoch 13/10000\n",
      "67/89 [=====================>........] - ETA: 0s - loss: 0.6467 - binary_crossentropy: 0.6467\n",
      "Epoch 13: val_loss did not improve from 0.60200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6374 - binary_crossentropy: 0.6374 - val_loss: 0.6033 - val_binary_crossentropy: 0.6033 - lr: 0.0010\n",
      "Epoch 14/10000\n",
      "73/89 [=======================>......] - ETA: 0s - loss: 0.6243 - binary_crossentropy: 0.6243\n",
      "Epoch 14: val_loss did not improve from 0.60200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6224 - binary_crossentropy: 0.6224 - val_loss: 0.6028 - val_binary_crossentropy: 0.6028 - lr: 0.0010\n",
      "Epoch 15/10000\n",
      "74/89 [=======================>......] - ETA: 0s - loss: 0.6181 - binary_crossentropy: 0.6181\n",
      "Epoch 15: val_loss did not improve from 0.60200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6224 - binary_crossentropy: 0.6224 - val_loss: 0.6033 - val_binary_crossentropy: 0.6033 - lr: 0.0010\n",
      "Epoch 16/10000\n",
      "69/89 [======================>.......] - ETA: 0s - loss: 0.5963 - binary_crossentropy: 0.5963\n",
      "Epoch 16: val_loss improved from 0.60200 to 0.59457, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6083 - binary_crossentropy: 0.6083 - val_loss: 0.5946 - val_binary_crossentropy: 0.5946 - lr: 0.0010\n",
      "Epoch 17/10000\n",
      "70/89 [======================>.......] - ETA: 0s - loss: 0.6116 - binary_crossentropy: 0.6116\n",
      "Epoch 17: val_loss improved from 0.59457 to 0.59186, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6212 - binary_crossentropy: 0.6212 - val_loss: 0.5919 - val_binary_crossentropy: 0.5919 - lr: 0.0010\n",
      "Epoch 18/10000\n",
      "66/89 [=====================>........] - ETA: 0s - loss: 0.6263 - binary_crossentropy: 0.6263\n",
      "Epoch 18: val_loss did not improve from 0.59186\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6200 - binary_crossentropy: 0.6200 - val_loss: 0.5924 - val_binary_crossentropy: 0.5924 - lr: 0.0010\n",
      "Epoch 19/10000\n",
      "69/89 [======================>.......] - ETA: 0s - loss: 0.6148 - binary_crossentropy: 0.6148\n",
      "Epoch 19: val_loss did not improve from 0.59186\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6123 - binary_crossentropy: 0.6123 - val_loss: 0.5946 - val_binary_crossentropy: 0.5946 - lr: 0.0010\n",
      "Epoch 20/10000\n",
      "74/89 [=======================>......] - ETA: 0s - loss: 0.6135 - binary_crossentropy: 0.6135\n",
      "Epoch 20: val_loss did not improve from 0.59186\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6191 - binary_crossentropy: 0.6191 - val_loss: 0.5952 - val_binary_crossentropy: 0.5952 - lr: 0.0010\n",
      "Epoch 21/10000\n",
      "66/89 [=====================>........] - ETA: 0s - loss: 0.6198 - binary_crossentropy: 0.6198\n",
      "Epoch 21: val_loss did not improve from 0.59186\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6261 - binary_crossentropy: 0.6261 - val_loss: 0.5967 - val_binary_crossentropy: 0.5967 - lr: 0.0010\n",
      "Epoch 22/10000\n",
      "59/89 [==================>...........] - ETA: 0s - loss: 0.6282 - binary_crossentropy: 0.6282\n",
      "Epoch 22: val_loss did not improve from 0.59186\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6247 - binary_crossentropy: 0.6247 - val_loss: 0.5942 - val_binary_crossentropy: 0.5942 - lr: 0.0010\n",
      "Epoch 23/10000\n",
      "63/89 [====================>.........] - ETA: 0s - loss: 0.6050 - binary_crossentropy: 0.6050\n",
      "Epoch 23: val_loss did not improve from 0.59186\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6148 - binary_crossentropy: 0.6148 - val_loss: 0.5946 - val_binary_crossentropy: 0.5946 - lr: 1.0000e-04\n",
      "Epoch 24/10000\n",
      "62/89 [===================>..........] - ETA: 0s - loss: 0.6166 - binary_crossentropy: 0.6166\n",
      "Epoch 24: val_loss did not improve from 0.59186\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6240 - binary_crossentropy: 0.6240 - val_loss: 0.5939 - val_binary_crossentropy: 0.5939 - lr: 1.0000e-04\n",
      "Epoch 25/10000\n",
      "68/89 [=====================>........] - ETA: 0s - loss: 0.6251 - binary_crossentropy: 0.6251\n",
      "Epoch 25: val_loss did not improve from 0.59186\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6269 - binary_crossentropy: 0.6269 - val_loss: 0.5924 - val_binary_crossentropy: 0.5924 - lr: 1.0000e-04\n",
      "Epoch 26/10000\n",
      "66/89 [=====================>........] - ETA: 0s - loss: 0.6382 - binary_crossentropy: 0.6382\n",
      "Epoch 26: val_loss did not improve from 0.59186\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6216 - binary_crossentropy: 0.6216 - val_loss: 0.5929 - val_binary_crossentropy: 0.5929 - lr: 1.0000e-04\n",
      "Epoch 27/10000\n",
      "72/89 [=======================>......] - ETA: 0s - loss: 0.6159 - binary_crossentropy: 0.6159\n",
      "Epoch 27: val_loss did not improve from 0.59186\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6205 - binary_crossentropy: 0.6205 - val_loss: 0.5927 - val_binary_crossentropy: 0.5927 - lr: 1.0000e-04\n",
      "Epoch 27: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7349ec705450>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#モデル学習\n",
    "#ミニバッチサイズを8としてlossが5 回連続改善しない場合に学習率を1/10\n",
    "#10回連続改善しなかった場合には強制終了\n",
    "seed_everything(seed=123)\n",
    "model = create_model()\n",
    "model.fit(x=x_tr,\n",
    "          y=y_tr,\n",
    "          validation_data=(x_va, y_va),\n",
    "          batch_size=8,\n",
    "          epochs=10000,\n",
    "          callbacks=[\n",
    "              ModelCheckpoint(filepath=\"model_keras.h5\", monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True, save_weights_only=True),\n",
    "              EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0, patience=10, verbose=1, restore_best_weights=True),\n",
    "              ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.1, patience=5, verbose=1),\n",
    "          ],\n",
    "          verbose=1,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a426a46d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:10.587775Z",
     "iopub.status.busy": "2023-04-05T14:42:10.587219Z",
     "iopub.status.idle": "2023-04-05T14:42:14.233416Z",
     "shell.execute_reply": "2023-04-05T14:42:14.232573Z"
    },
    "papermill": {
     "duration": 3.686856,
     "end_time": "2023-04-05T14:42:14.235898",
     "exception": false,
     "start_time": "2023-04-05T14:42:10.549042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 988us/step\n",
      "accuracy: 0.6872\n"
     ]
    }
   ],
   "source": [
    "#モデルの評価\n",
    "y_va_pred = model.predict(x_va, batch_size=8, verbose=1)\n",
    "print(\"accuracy: {:.4f}\".format(accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb67bd",
   "metadata": {
    "papermill": {
     "duration": 0.034347,
     "end_time": "2023-04-05T14:42:14.306231",
     "exception": false,
     "start_time": "2023-04-05T14:42:14.271884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ニューラルネットワークの適用例：②埋め込み層ありのネットワークモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eafeff87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:14.377338Z",
     "iopub.status.busy": "2023-04-05T14:42:14.376995Z",
     "iopub.status.idle": "2023-04-05T14:42:14.387877Z",
     "shell.execute_reply": "2023-04-05T14:42:14.387189Z"
    },
    "papermill": {
     "duration": 0.049021,
     "end_time": "2023-04-05T14:42:14.389900",
     "exception": false,
     "start_time": "2023-04-05T14:42:14.340879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "# データセット作成\n",
    "x_train = df_train[[\"Pclass\", \"Age\", \"Cabin\"]]\n",
    "y_train = df_train[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a3618ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:14.462826Z",
     "iopub.status.busy": "2023-04-05T14:42:14.462455Z",
     "iopub.status.idle": "2023-04-05T14:42:14.471973Z",
     "shell.execute_reply": "2023-04-05T14:42:14.470539Z"
    },
    "papermill": {
     "duration": 0.048487,
     "end_time": "2023-04-05T14:42:14.474356",
     "exception": false,
     "start_time": "2023-04-05T14:42:14.425869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#数値データの前処理\n",
    "# 欠損値補間\n",
    "x_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n",
    "\n",
    "# 正規化\n",
    "for col in [\"Pclass\", \"Age\"]:\n",
    "    value_min = x_train[col].min()\n",
    "    value_max = x_train[col].max()\n",
    "    x_train[col] = (x_train[col] - value_min) / (value_max - value_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40eb30a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:14.546335Z",
     "iopub.status.busy": "2023-04-05T14:42:14.545988Z",
     "iopub.status.idle": "2023-04-05T14:42:14.554844Z",
     "shell.execute_reply": "2023-04-05T14:42:14.553749Z"
    },
    "papermill": {
     "duration": 0.048058,
     "end_time": "2023-04-05T14:42:14.556899",
     "exception": false,
     "start_time": "2023-04-05T14:42:14.508841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A10' 'A14' 'A16' 'A19' 'A20' 'A23' 'A24' 'A26' 'A31' 'A32' 'A34' 'A36'\n",
      " 'A5' 'A6' 'A7' 'B101' 'B102' 'B18' 'B19' 'B20' 'B22' 'B28' 'B3' 'B30'\n",
      " 'B35' 'B37' 'B38' 'B39' 'B4' 'B41' 'B42' 'B49' 'B5' 'B50' 'B51 B53 B55'\n",
      " 'B57 B59 B63 B66' 'B58 B60' 'B69' 'B71' 'B73' 'B77' 'B78' 'B79' 'B80'\n",
      " 'B82 B84' 'B86' 'B94' 'B96 B98' 'C101' 'C103' 'C104' 'C106' 'C110' 'C111'\n",
      " 'C118' 'C123' 'C124' 'C125' 'C126' 'C128' 'C148' 'C2' 'C22 C26'\n",
      " 'C23 C25 C27' 'C30' 'C32' 'C45' 'C46' 'C47' 'C49' 'C50' 'C52' 'C54'\n",
      " 'C62 C64' 'C65' 'C68' 'C7' 'C70' 'C78' 'C82' 'C83' 'C85' 'C86' 'C87'\n",
      " 'C90' 'C91' 'C92' 'C93' 'C95' 'C99' 'D' 'D10 D12' 'D11' 'D15' 'D17' 'D19'\n",
      " 'D20' 'D21' 'D26' 'D28' 'D30' 'D33' 'D35' 'D36' 'D37' 'D45' 'D46' 'D47'\n",
      " 'D48' 'D49' 'D50' 'D56' 'D6' 'D7' 'D9' 'E10' 'E101' 'E12' 'E121' 'E17'\n",
      " 'E24' 'E25' 'E31' 'E33' 'E34' 'E36' 'E38' 'E40' 'E44' 'E46' 'E49' 'E50'\n",
      " 'E58' 'E63' 'E67' 'E68' 'E77' 'E8' 'F E69' 'F G63' 'F G73' 'F2' 'F33'\n",
      " 'F38' 'F4' 'G6' 'None' 'T']\n",
      "count: 148\n"
     ]
    }
   ],
   "source": [
    "#カテゴリ変数の前処理　欠損値をnoneにした後にlabel-encoding\n",
    "# 欠損値補間\n",
    "x_train[\"Cabin\"] = x_train[\"Cabin\"].fillna(\"None\")\n",
    "\n",
    "# label-encoding\n",
    "le = LabelEncoder()\n",
    "le.fit(x_train[[\"Cabin\"]])\n",
    "x_train[\"Cabin\"] = le.transform(x_train[\"Cabin\"])\n",
    "\n",
    "print(le.classes_)\n",
    "print(\"count:\", len(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b405c672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:14.627655Z",
     "iopub.status.busy": "2023-04-05T14:42:14.626925Z",
     "iopub.status.idle": "2023-04-05T14:42:14.640338Z",
     "shell.execute_reply": "2023-04-05T14:42:14.639131Z"
    },
    "papermill": {
     "duration": 0.050979,
     "end_time": "2023-04-05T14:42:14.642230",
     "exception": false,
     "start_time": "2023-04-05T14:42:14.591251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 2) (179, 2) (712, 1) (179, 1) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "#学習データと検証データの分離\n",
    "x_train_num, x_train_cat = x_train[[\"Pclass\", \"Age\"]], x_train[[\"Cabin\"]]\n",
    "\n",
    "x_num_tr, x_num_va, x_cat_tr, x_cat_va, y_tr, y_va = \\\n",
    "   train_test_split(x_train_num, x_train_cat, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_num_tr.shape, x_num_va.shape, x_cat_tr.shape, x_cat_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bb1a3e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:14.712839Z",
     "iopub.status.busy": "2023-04-05T14:42:14.712444Z",
     "iopub.status.idle": "2023-04-05T14:42:14.908149Z",
     "shell.execute_reply": "2023-04-05T14:42:14.906869Z"
    },
    "papermill": {
     "duration": 0.235377,
     "end_time": "2023-04-05T14:42:14.911990",
     "exception": false,
     "start_time": "2023-04-05T14:42:14.676613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 10)           30          ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None,)             0           ['input_4[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 10)          40          ['dense_8[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 74)           10952       ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 10)           0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 74)           0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 10)           110         ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 74)           0           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 84)           0           ['dense_9[0][0]',                \n",
      "                                                                  'flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 50)           4250        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 50)          200         ['dense_10[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 50)           0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 20)           1020        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 20)          80          ['dense_11[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 20)           0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1)            21          ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,703\n",
      "Trainable params: 16,543\n",
      "Non-trainable params: 160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#組み込み層ありのモデル定義\n",
    "def create_model_embedding():\n",
    "    ################# num\n",
    "    input_num = Input(shape=(2,))\n",
    "    layer_num = Dense(10, activation=\"relu\")(input_num)\n",
    "    layer_num = BatchNormalization()(layer_num)\n",
    "    layer_num = Dropout(0.2)(layer_num)\n",
    "    layer_num = Dense(10, activation=\"relu\")(layer_num)\n",
    "\n",
    "    ################# cat\n",
    "    input_cat = Input(shape=(1,))\n",
    "    layer_cat = input_cat[:, 0]\n",
    "    layer_cat = Embedding(input_dim=148, output_dim=74)(layer_cat)\n",
    "    layer_cat = Dropout(0.2)(layer_cat)\n",
    "    layer_cat = Flatten()(layer_cat)\n",
    "\n",
    "    ################# concat\n",
    "    hidden_layer = Concatenate()([layer_num, layer_cat])\n",
    "    hidden_layer = Dense(50, activation=\"relu\")(hidden_layer)\n",
    "    hidden_layer = BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = Dropout(0.1)(hidden_layer)\n",
    "    hidden_layer = Dense(20, activation=\"relu\")(hidden_layer)\n",
    "    hidden_layer = BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = Dropout(0.1)(hidden_layer)\n",
    "    output_layer = Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "    model = Model(inputs=[input_num, input_cat],\n",
    "                  outputs=output_layer,\n",
    "                 )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"binary_crossentropy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model_embedding()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "210687cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:14.991816Z",
     "iopub.status.busy": "2023-04-05T14:42:14.991454Z",
     "iopub.status.idle": "2023-04-05T14:42:21.599193Z",
     "shell.execute_reply": "2023-04-05T14:42:21.597634Z"
    },
    "papermill": {
     "duration": 6.65109,
     "end_time": "2023-04-05T14:42:21.601605",
     "exception": false,
     "start_time": "2023-04-05T14:42:14.950515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "74/89 [=======================>......] - ETA: 0s - loss: 0.7878 - binary_crossentropy: 0.7878\n",
      "Epoch 1: val_loss improved from inf to 0.65931, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 2s 6ms/step - loss: 0.7856 - binary_crossentropy: 0.7856 - val_loss: 0.6593 - val_binary_crossentropy: 0.6593 - lr: 0.0010\n",
      "Epoch 2/10000\n",
      "80/89 [=========================>....] - ETA: 0s - loss: 0.6664 - binary_crossentropy: 0.6664\n",
      "Epoch 2: val_loss improved from 0.65931 to 0.65164, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6650 - binary_crossentropy: 0.6650 - val_loss: 0.6516 - val_binary_crossentropy: 0.6516 - lr: 0.0010\n",
      "Epoch 3/10000\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.6562 - binary_crossentropy: 0.6562\n",
      "Epoch 3: val_loss improved from 0.65164 to 0.64750, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6511 - binary_crossentropy: 0.6511 - val_loss: 0.6475 - val_binary_crossentropy: 0.6475 - lr: 0.0010\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.6343 - binary_crossentropy: 0.6343\n",
      "Epoch 4: val_loss improved from 0.64750 to 0.63007, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6343 - binary_crossentropy: 0.6343 - val_loss: 0.6301 - val_binary_crossentropy: 0.6301 - lr: 0.0010\n",
      "Epoch 5/10000\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.6034 - binary_crossentropy: 0.6034\n",
      "Epoch 5: val_loss improved from 0.63007 to 0.60511, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_crossentropy: 0.6016 - val_loss: 0.6051 - val_binary_crossentropy: 0.6051 - lr: 0.0010\n",
      "Epoch 6/10000\n",
      "88/89 [============================>.] - ETA: 0s - loss: 0.5998 - binary_crossentropy: 0.5998\n",
      "Epoch 6: val_loss improved from 0.60511 to 0.59476, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5963 - binary_crossentropy: 0.5963 - val_loss: 0.5948 - val_binary_crossentropy: 0.5948 - lr: 0.0010\n",
      "Epoch 7/10000\n",
      "83/89 [==========================>...] - ETA: 0s - loss: 0.5804 - binary_crossentropy: 0.5804\n",
      "Epoch 7: val_loss did not improve from 0.59476\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5820 - binary_crossentropy: 0.5820 - val_loss: 0.6200 - val_binary_crossentropy: 0.6200 - lr: 0.0010\n",
      "Epoch 8/10000\n",
      "79/89 [=========================>....] - ETA: 0s - loss: 0.5702 - binary_crossentropy: 0.5702\n",
      "Epoch 8: val_loss did not improve from 0.59476\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5714 - binary_crossentropy: 0.5714 - val_loss: 0.6299 - val_binary_crossentropy: 0.6299 - lr: 0.0010\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.5379 - binary_crossentropy: 0.5379\n",
      "Epoch 9: val_loss did not improve from 0.59476\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5379 - binary_crossentropy: 0.5379 - val_loss: 0.6270 - val_binary_crossentropy: 0.6270 - lr: 0.0010\n",
      "Epoch 10/10000\n",
      "88/89 [============================>.] - ETA: 0s - loss: 0.5542 - binary_crossentropy: 0.5542\n",
      "Epoch 10: val_loss did not improve from 0.59476\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5529 - binary_crossentropy: 0.5529 - val_loss: 0.6350 - val_binary_crossentropy: 0.6350 - lr: 0.0010\n",
      "Epoch 11/10000\n",
      "75/89 [========================>.....] - ETA: 0s - loss: 0.5276 - binary_crossentropy: 0.5276\n",
      "Epoch 11: val_loss did not improve from 0.59476\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5355 - binary_crossentropy: 0.5355 - val_loss: 0.6409 - val_binary_crossentropy: 0.6409 - lr: 0.0010\n",
      "Epoch 12/10000\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.5431 - binary_crossentropy: 0.5431\n",
      "Epoch 12: val_loss did not improve from 0.59476\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5420 - binary_crossentropy: 0.5420 - val_loss: 0.6339 - val_binary_crossentropy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 13/10000\n",
      "77/89 [========================>.....] - ETA: 0s - loss: 0.5455 - binary_crossentropy: 0.5455\n",
      "Epoch 13: val_loss did not improve from 0.59476\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5559 - binary_crossentropy: 0.5559 - val_loss: 0.6376 - val_binary_crossentropy: 0.6376 - lr: 1.0000e-04\n",
      "Epoch 14/10000\n",
      "72/89 [=======================>......] - ETA: 0s - loss: 0.5179 - binary_crossentropy: 0.5179\n",
      "Epoch 14: val_loss did not improve from 0.59476\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5331 - binary_crossentropy: 0.5331 - val_loss: 0.6380 - val_binary_crossentropy: 0.6380 - lr: 1.0000e-04\n",
      "Epoch 15/10000\n",
      "71/89 [======================>.......] - ETA: 0s - loss: 0.5477 - binary_crossentropy: 0.5477\n",
      "Epoch 15: val_loss did not improve from 0.59476\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5477 - binary_crossentropy: 0.5477 - val_loss: 0.6343 - val_binary_crossentropy: 0.6343 - lr: 1.0000e-04\n",
      "Epoch 16/10000\n",
      "83/89 [==========================>...] - ETA: 0s - loss: 0.5458 - binary_crossentropy: 0.5458\n",
      "Epoch 16: val_loss did not improve from 0.59476\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5485 - binary_crossentropy: 0.5485 - val_loss: 0.6356 - val_binary_crossentropy: 0.6356 - lr: 1.0000e-04\n",
      "Epoch 16: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7349e6fef910>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#モデル学習\n",
    "seed_everything(seed=123)\n",
    "model = create_model_embedding()\n",
    "model.fit(x=[x_num_tr, x_cat_tr],\n",
    "          y=y_tr,\n",
    "          validation_data=([x_num_va, x_cat_va], y_va),\n",
    "          batch_size=8,\n",
    "          epochs=10000,\n",
    "          callbacks=[\n",
    "              ModelCheckpoint(filepath=\"model_keras_embedding.h5\", monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True, save_weights_only=True),\n",
    "              EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0, patience=10, verbose=1, restore_best_weights=True),\n",
    "              ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.1, patience=5, verbose=1),\n",
    "          ],\n",
    "          verbose=1,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f23f5879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:21.694820Z",
     "iopub.status.busy": "2023-04-05T14:42:21.694171Z",
     "iopub.status.idle": "2023-04-05T14:42:22.347800Z",
     "shell.execute_reply": "2023-04-05T14:42:22.346348Z"
    },
    "papermill": {
     "duration": 0.702631,
     "end_time": "2023-04-05T14:42:22.349868",
     "exception": false,
     "start_time": "2023-04-05T14:42:21.647237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step\n",
      "accuracy: 0.6983\n"
     ]
    }
   ],
   "source": [
    "#学習モデル評価\n",
    "y_va_pred = model.predict([x_num_va, x_cat_va], batch_size=8, verbose=1)\n",
    "print(\"accuracy: {:.4f}\".format(accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415dc9c",
   "metadata": {
    "papermill": {
     "duration": 0.044991,
     "end_time": "2023-04-05T14:42:22.439217",
     "exception": false,
     "start_time": "2023-04-05T14:42:22.394226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# アンサンブル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cea47d",
   "metadata": {
    "papermill": {
     "duration": 0.045327,
     "end_time": "2023-04-05T14:42:22.529564",
     "exception": false,
     "start_time": "2023-04-05T14:42:22.484237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 単純平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53e6364e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:22.622639Z",
     "iopub.status.busy": "2023-04-05T14:42:22.621994Z",
     "iopub.status.idle": "2023-04-05T14:42:22.643363Z",
     "shell.execute_reply": "2023-04-05T14:42:22.642184Z"
    },
    "papermill": {
     "duration": 0.068757,
     "end_time": "2023-04-05T14:42:22.645289",
     "exception": false,
     "start_time": "2023-04-05T14:42:22.576532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3\n",
       "0     1  0.683821  0.874443  0.859939\n",
       "1     0  0.540691  0.113419  0.197144\n",
       "2     0  0.310541  0.334798  0.599304\n",
       "3     0  0.043486  0.170622  0.378528\n",
       "4     0  0.550847  0.354703  0.598860"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#モデルの予測値を持つデータフレームを乱数で作成\n",
    "np.random.seed(123)\n",
    "df = pd.DataFrame({\n",
    "    \"true\": [0]*700 + [1]*300,\n",
    "    \"pred1\":np.arange(1000) + np.random.rand(1000)*1200,\n",
    "    \"pred2\":np.arange(1000) + np.random.rand(1000)*1000,\n",
    "    \"pred3\":np.arange(1000) + np.random.rand(1000)*800,\n",
    "})\n",
    "df[\"pred1\"] = np.clip(df[\"pred1\"]/df[\"pred1\"].max(), 0, 1)\n",
    "df[\"pred2\"] = np.clip(df[\"pred2\"]/df[\"pred2\"].max(), 0, 1)\n",
    "df[\"pred3\"] = np.clip(df[\"pred3\"]/df[\"pred3\"].max(), 0, 1)\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.8, stratify=df[\"true\"], random_state=123)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e24f188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:22.735119Z",
     "iopub.status.busy": "2023-04-05T14:42:22.734407Z",
     "iopub.status.idle": "2023-04-05T14:42:22.746352Z",
     "shell.execute_reply": "2023-04-05T14:42:22.745189Z"
    },
    "papermill": {
     "duration": 0.059559,
     "end_time": "2023-04-05T14:42:22.748619",
     "exception": false,
     "start_time": "2023-04-05T14:42:22.689060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred_ensemble1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.806068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.283752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.414881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.197545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "      <td>0.501470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3  pred_ensemble1\n",
       "0     1  0.683821  0.874443  0.859939        0.806068\n",
       "1     0  0.540691  0.113419  0.197144        0.283752\n",
       "2     0  0.310541  0.334798  0.599304        0.414881\n",
       "3     0  0.043486  0.170622  0.378528        0.197545\n",
       "4     0  0.550847  0.354703  0.598860        0.501470"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#単純移動平均によるアンサンブル\n",
    "df_train[\"pred_ensemble1\"] = (df_train[\"pred1\"] + df_train[\"pred2\"] + df_train[\"pred3\"]) / 3\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "761b6e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:22.839170Z",
     "iopub.status.busy": "2023-04-05T14:42:22.838488Z",
     "iopub.status.idle": "2023-04-05T14:42:22.850547Z",
     "shell.execute_reply": "2023-04-05T14:42:22.848872Z"
    },
    "papermill": {
     "duration": 0.059484,
     "end_time": "2023-04-05T14:42:22.852548",
     "exception": false,
     "start_time": "2023-04-05T14:42:22.793064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9585\n"
     ]
    }
   ],
   "source": [
    "#アンサンブル用の精度評価関数と精度評価\n",
    "def evaluate_ensemble(input_df, col_pred):\n",
    "    print(\"[auc] model1:{:.4f}, model2:{:.4f}, model3:{:.4f} -> ensemble:{:.4f}\".format(\n",
    "        roc_auc_score(input_df[\"true\"], input_df[\"pred1\"]),\n",
    "        roc_auc_score(input_df[\"true\"], input_df[\"pred2\"]),\n",
    "        roc_auc_score(input_df[\"true\"], input_df[\"pred3\"]),\n",
    "        roc_auc_score(input_df[\"true\"], input_df[col_pred]),\n",
    "    ))\n",
    "\n",
    "evaluate_ensemble(df_train, col_pred=\"pred_ensemble1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eeb513b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:22.944343Z",
     "iopub.status.busy": "2023-04-05T14:42:22.943710Z",
     "iopub.status.idle": "2023-04-05T14:42:22.955159Z",
     "shell.execute_reply": "2023-04-05T14:42:22.954004Z"
    },
    "papermill": {
     "duration": 0.060147,
     "end_time": "2023-04-05T14:42:22.957579",
     "exception": false,
     "start_time": "2023-04-05T14:42:22.897432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9396\n"
     ]
    }
   ],
   "source": [
    "#推論時のアンサンブル処理と精度評価\n",
    "df_test[\"pred_ensemble1\"] = (df_test[\"pred1\"] + df_test[\"pred2\"] + df_test[\"pred3\"]) / 3\n",
    "evaluate_ensemble(df_test, col_pred=\"pred_ensemble1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e2773",
   "metadata": {
    "papermill": {
     "duration": 0.045112,
     "end_time": "2023-04-05T14:42:23.048462",
     "exception": false,
     "start_time": "2023-04-05T14:42:23.003350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 重み付き平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90e8b18c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:23.138879Z",
     "iopub.status.busy": "2023-04-05T14:42:23.138536Z",
     "iopub.status.idle": "2023-04-05T14:42:23.154789Z",
     "shell.execute_reply": "2023-04-05T14:42:23.153510Z"
    },
    "papermill": {
     "duration": 0.064216,
     "end_time": "2023-04-05T14:42:23.157002",
     "exception": false,
     "start_time": "2023-04-05T14:42:23.092786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.3 0.4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred_ensemble2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.811455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.275091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.433324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.215643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "      <td>0.511209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3  pred_ensemble2\n",
       "0     1  0.683821  0.874443  0.859939        0.811455\n",
       "1     0  0.540691  0.113419  0.197144        0.275091\n",
       "2     0  0.310541  0.334798  0.599304        0.433324\n",
       "3     0  0.043486  0.170622  0.378528        0.215643\n",
       "4     0  0.550847  0.354703  0.598860        0.511209"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重み付きに平均によるアンサンブル\n",
    "weight = [0.3, 0.3, 0.4]\n",
    "weight = weight / np.sum(weight)\n",
    "print(weight)\n",
    "\n",
    "df_train[\"pred_ensemble2\"] = df_train[\"pred1\"] * weight[0] + \\\n",
    "                             df_train[\"pred2\"] * weight[1] + \\\n",
    "                             df_train[\"pred3\"] * weight[2]\n",
    "df_train[[\"true\",\"pred1\",\"pred2\",\"pred3\",\"pred_ensemble2\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bea93a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:23.248905Z",
     "iopub.status.busy": "2023-04-05T14:42:23.248565Z",
     "iopub.status.idle": "2023-04-05T14:42:23.261129Z",
     "shell.execute_reply": "2023-04-05T14:42:23.259733Z"
    },
    "papermill": {
     "duration": 0.060649,
     "end_time": "2023-04-05T14:42:23.263354",
     "exception": false,
     "start_time": "2023-04-05T14:42:23.202705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9614\n"
     ]
    }
   ],
   "source": [
    "# アンサンブルの精度評価\n",
    "evaluate_ensemble(df_train, col_pred=\"pred_ensemble2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72da9e0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:23.356015Z",
     "iopub.status.busy": "2023-04-05T14:42:23.355270Z",
     "iopub.status.idle": "2023-04-05T14:42:23.371885Z",
     "shell.execute_reply": "2023-04-05T14:42:23.370893Z"
    },
    "papermill": {
     "duration": 0.065929,
     "end_time": "2023-04-05T14:42:23.373868",
     "exception": false,
     "start_time": "2023-04-05T14:42:23.307939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9420\n"
     ]
    }
   ],
   "source": [
    "#推論時のアンサンブル処理と精度評価\n",
    "df_test[\"pred_ensemble2\"] = df_test[\"pred1\"] * weight[0] + \\\n",
    "                            df_test[\"pred2\"] * weight[1] + \\\n",
    "                            df_test[\"pred3\"] * weight[2]\n",
    "evaluate_ensemble(df_test, col_pred=\"pred_ensemble2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1bdb44",
   "metadata": {
    "papermill": {
     "duration": 0.044535,
     "end_time": "2023-04-05T14:42:23.473507",
     "exception": false,
     "start_time": "2023-04-05T14:42:23.428972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## スタッキング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49711b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:23.565439Z",
     "iopub.status.busy": "2023-04-05T14:42:23.564948Z",
     "iopub.status.idle": "2023-04-05T14:42:23.615316Z",
     "shell.execute_reply": "2023-04-05T14:42:23.614334Z"
    },
    "papermill": {
     "duration": 0.098652,
     "end_time": "2023-04-05T14:42:23.617171",
     "exception": false,
     "start_time": "2023-04-05T14:42:23.518519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred_ensemble3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.745020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.206734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "      <td>0.303498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3  pred_ensemble3\n",
       "0     1  0.683821  0.874443  0.859939        0.745020\n",
       "1     0  0.540691  0.113419  0.197144        0.000000\n",
       "2     0  0.310541  0.334798  0.599304        0.206734\n",
       "3     0  0.043486  0.170622  0.378528        0.000000\n",
       "4     0  0.550847  0.354703  0.598860        0.303498"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スタッキングによるいアンサンブル（予測値から値を予測するモデルを利用する方法）\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "x, y = df_train[[\"pred1\", \"pred2\", \"pred3\"]], df_train[[\"true\"]]\n",
    "oof = np.zeros(len(x))\n",
    "models = []\n",
    "\n",
    "cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x, y))\n",
    "for nfold in np.arange(5):\n",
    "    # 学習データと検証データの分離\n",
    "    idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "    x_tr, y_tr = x.loc[idx_tr, :], y.loc[idx_tr, :]\n",
    "    x_va, y_va = x.loc[idx_va, :], y.loc[idx_va, :]\n",
    "    \n",
    "    # モデル学習\n",
    "    model = Lasso(alpha=0.01)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    models.append(model)\n",
    "    \n",
    "    # 検証データの予測値算出\n",
    "    y_va_pred = model.predict(x_va)\n",
    "    oof[idx_va] = y_va_pred\n",
    "    \n",
    "df_train[\"pred_ensemble3\"] = oof\n",
    "df_train[\"pred_ensemble3\"] = df_train[\"pred_ensemble3\"].clip(lower=0, upper=1)\n",
    "df_train[[\"true\",\"pred1\",\"pred2\",\"pred3\",\"pred_ensemble3\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc3f06e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:23.710221Z",
     "iopub.status.busy": "2023-04-05T14:42:23.709830Z",
     "iopub.status.idle": "2023-04-05T14:42:23.721422Z",
     "shell.execute_reply": "2023-04-05T14:42:23.720059Z"
    },
    "papermill": {
     "duration": 0.061438,
     "end_time": "2023-04-05T14:42:23.724158",
     "exception": false,
     "start_time": "2023-04-05T14:42:23.662720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9577\n"
     ]
    }
   ],
   "source": [
    "#アンサンブル精度評価\n",
    "evaluate_ensemble(df_train, col_pred=\"pred_ensemble3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "816d802e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:42:23.817488Z",
     "iopub.status.busy": "2023-04-05T14:42:23.817102Z",
     "iopub.status.idle": "2023-04-05T14:42:23.842776Z",
     "shell.execute_reply": "2023-04-05T14:42:23.841659Z"
    },
    "papermill": {
     "duration": 0.075437,
     "end_time": "2023-04-05T14:42:23.845243",
     "exception": false,
     "start_time": "2023-04-05T14:42:23.769806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9437\n"
     ]
    }
   ],
   "source": [
    "#推論時のアンサンブル処理と精度評価\n",
    "df_test[\"pred_ensemble3\"] = 0\n",
    "for model in models:\n",
    "    df_test[\"pred_ensemble3\"] += model.predict(df_test[[\"pred1\", \"pred2\", \"pred3\"]]) / len(models)\n",
    "df_test[\"pred_ensemble3\"] = df_test[\"pred_ensemble3\"].clip(lower=0, upper=1)\n",
    "evaluate_ensemble(df_test, col_pred=\"pred_ensemble3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528340c",
   "metadata": {
    "papermill": {
     "duration": 0.045189,
     "end_time": "2023-04-05T14:42:23.936046",
     "exception": false,
     "start_time": "2023-04-05T14:42:23.890857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 167.710161,
   "end_time": "2023-04-05T14:42:27.565856",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-05T14:39:39.855695",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
